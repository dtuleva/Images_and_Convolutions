import numpy as np
import matplotlib.pyplot as plt
import cv2 
import tensorflow as tf

from skimage.io import imread
from matplotlib.colors import TwoSlopeNorm
from scipy.ndimage import convolve, correlate, sobel


from tensorflow.keras import datasets, layers, models

















def plot_image_subplots(images, titles=None, subplot_kwargs=None, nrows=1, ncols=3, figsize_hor=12, figsize_ver=6, no_ticks=True):
    """
    Plots a grid of images with titles, allowing for different keyword arguments for each subplot.

    Parameters:
    images : list of array-like
        List of images to plot.
    titles : list of str, optional
        List of titles for each subplot. Default is None.
    plot_kwargs : list of dict, optional
        List of dictionaries with keyword arguments for plt.imshow for each subplot. 
        If not provided, a default colormap of 'gray' is used.
    nrows : int, optional
        Number of rows in the subplot grid. Default is 1.
    ncols : int, optional
        Number of columns in the subplot grid. Default is 3.
    figsize_hor : int, optional
        Horizontal size of the entire figure. Default is 12.
    figsize_ver : int, optional
        Vertical size of the entire figure. Default is 6.
    no_ticks : bool, optional
        If True, removes ticks from the plots. Default is True.

    Example:
    plot_image_subplots(
        images=[image_1, image_2, image_3],
        titles=["Title 1", "Title 2", "Title 3"],
        plot_kwargs=[
            {"cmap": "gray"},
            {"cmap": "Reds_r", "vmin": 0, "vmax": 1},
            {"cmap": "Blues_r", "vmin": -1, "vmax": 1}
        ],
        nrows=1,
        ncols=3,
        figsize_hor=15,
        figsize_ver=5
    )
    """
    if titles is None:
        titles = ["" for _ in images]
    else:
        assert len(images) == len(titles), "Number of images not equal to number of titles"

    if subplot_kwargs is None:
        subplot_kwargs = [{} for _ in images]
    else:
        assert len(images) == len(subplot_kwargs), "Number of images not equal to number of plot_kwargs"

    for kwargs in subplot_kwargs:
        if "cmap" not in kwargs:
            kwargs["cmap"] = "gray"

    fig, axs = plt.subplots(nrows, ncols, figsize=(figsize_hor, figsize_ver))
    axs = axs.flatten()

    for i, (image, title) in enumerate(zip(images, titles)):
        axs[i].imshow(image, **subplot_kwargs[i])
        axs[i].set_title(title)

    if no_ticks:
        plt.setp(axs, xticks=[], yticks=[])

    plt.tight_layout()
    plt.show()



def plot_convolutions(image, filters, titles = None, subplot_kwargs = None, **plot_kwargs):
    """
    Plot images resulting from convolution with given filters.
    """
    conv_results = [(convolve(image, filter)) for filter in filters]
    plot_image_subplots(conv_results, titles, subplot_kwargs, **plot_kwargs)


def plot_heatmaps(arrays, titles = None, nrows = 1, ncols = 2, figsize_hor = 12, figsize_ver = 3, cmap_limit = 0.1):
    """
    Plots several heatmaps in subplots with a common colorbar.

    array_info : list of tuples
            - filter (array-like)
            - title (str)
            
    Example input:
        plot_heatmaps(
        [
            (filter1, "Filter 1"), 
            (filter2, "Filter 2")
        ], 
        nrows=1, 
        ncols=2
        )
    """
    if titles is None:
        titles = ["" for _ in arrays]
    else:
        assert len(arrays) == len(titles), "Number of arrays not equal to number of titles"

    # Create the figure and axes
    fig, axs = plt.subplots(nrows, ncols, figsize = (figsize_hor, figsize_ver), layout = "compressed")
    if len(arrays) > 1:
        axs = axs.flatten()
    else:
        axs = [axs]

    # Find the global min and max values across all data for common scaling
    global_min = min(data.min() for data in arrays)
    global_max = max(data.max() for data in arrays)

    global_abs = max([abs(global_min), global_max])

    # Create a common normalization
    norm = TwoSlopeNorm(vmin = - cmap_limit - global_abs, vmax = cmap_limit + global_abs, vcenter = 0)

    # Plot each data array
    for ax, array, title in zip(axs, arrays, titles):
        cax = ax.imshow(array, cmap = "seismic", norm = norm)
        ax.set_title(title)
    
    # Add a single colorbar
    cbar = fig.colorbar(cax, ax=axs[:len(arrays)])
    
    # Remove axis ticks
    plt.setp(axs, xticks=[], yticks=[])
    
 
    plt.show()










































cat_image_url = "https://d17fnq9dkz9hgj.cloudfront.net/uploads/2012/11/140272627-grooming-needs-senior-cat-632x475.jpg"
cat_image = imread(cat_image_url)
cat_image.shape


plt.imshow(cat_image)
plt.show()


# normalize
cat_image = cat_image / 255

# split channels
cat_image_r, cat_image_g, cat_image_b = [cat_image[:, :, i] for i in range(3)]




plot_image_subplots(
    images=[cat_image_r, cat_image_g, cat_image_b],
    titles=["Red Channel", "Green Channel", "Blue Channel"],
    subplot_kwargs=[{"cmap": "Reds_r"}, {"cmap": "Greens_r"}, {"cmap": "Blues_r"}],
)



cat_image_gray = (cat_image_r + cat_image_g + cat_image_b) / 3.0  
cat_image_gray_corrected = (0.299 * cat_image_r + 
                            0.587 * cat_image_g + 
                            0.114 * cat_image_b)


plot_image_subplots(
    images=[cat_image_gray, cat_image_gray_corrected],
    titles=["Average grayscale image", "Gamma-corrected grayscale image"],
    ncols=2
)









# let's call it cat
cat = cat_image_gray_corrected
cat.shape


# Function to keep the range of pixel values; (0, 1) by default
def limit_range(pixel_value, min_value = 0, max_value = 1):  
    if pixel_value < min_value:
        pixel_value = min_value
    elif pixel_value > max_value:
        pixel_value = max_value
    return pixel_value

limit_range = np.vectorize(limit_range)


def custom_map(px):
    if px < 0.15:
        return 0
    elif px < 0.3:
        return 0.15
    elif px < 0.7:
        return px
    elif px < 0.85:
        return 0.7
    return 1

custom_map = np.vectorize(custom_map)


def black_and_white(px, limit_value = 0.5):
    if px < limit_value:
        return 0
    return 1

black_and_white = np.vectorize(black_and_white)


cat_add = limit_range(cat + 0.3)
cat_subtract = limit_range(cat - 0.1)
cat_multiply = limit_range(cat * 2)
cat_divide = limit_range(cat / 2)
cat_power_light = limit_range(cat ** 0.3)
cat_power_dark = limit_range(cat ** 3)
cat_map = custom_map(cat)
cat_black_and_white = black_and_white(cat)
cat_invert = cat * -1



plot_image_subplots(
    images=[
        cat,
        limit_range(cat + 0.3),
        limit_range(cat - 0.1),
        custom_map(cat),
        limit_range(cat * 2),
        limit_range(cat / 2),
        black_and_white(cat),
        limit_range(cat ** 0.3),
        limit_range(cat ** 3)
    ],
    titles=[
        "Original Image",
        "Add - Brightness Increased",
        "Subtract - Brightness Decreased",
        "Custom Color Mapping",
        "Multiply - Contrast Increased",
        "Divide - Contrast Decreased",
        "Black and White",
        "Power < 1 - Gamma Light Correction",
        "Power > 1 - Gamma Dark Correction"
    ],
    nrows=3,
    figsize_ver=10
)




plot_image_subplots(
    images=[
        cat,
        cat * -1
    ],
    titles=[
        "Original Image",
        "Inverted"
    ],
    ncols=2
)



box_url = "https://shmector.com/_ph/10/356948332.png"
box_raw = imread(box_url)
box_raw.shape


#Normalize
box_image = box_raw.copy() / 255
#grayscale
box_image = box_image.mean(axis=2)



# our box is too big take every * pixel
box_image.shape


def downsample_image(image, n):
    return image[::n, ::n]


box = downsample_image(box_image, 4)
box.shape


# pad
pad_x = 100
pad_y = 125


box = np.pad(
    box, 
    ((pad_x, 475-box.shape[0]-pad_x), (pad_y, 632-box.shape[1]-pad_y)), 
    'constant', constant_values = 1
    )




plot_image_subplots(
    images=[
        box_raw,
        box_image,
        box
    ],
    titles=[
        "Raw",
        "Grayscale",
        "Downsampled and Padded"
    ],
    no_ticks=False
)



plot_image_subplots(
    images=[
        cat,
        cat + box,
        cat - box,
        box - cat,
        box,
        cat * box,
        cat ** box,
        box ** cat
    ],
    titles=[
        "Cat",
        "Cat + Box",
        "Cat - Box",
        "Box - Cat",
        "Box",
        r"Cat $ \times $ Box",
        r"$Cat^{Box}$",
        r"$Box^{Cat}$"
    ],
    nrows=2,
    ncols=4
)






conv_filter = np.array([
    [1, 2, -3],
    [4, 5, -6],
    [7, 8, -9]
])





plt.imshow(convolve(cat, conv_filter), cmap = "gray")
plt.show()








def convolve_np(image, filter, flip_filter = True):
    n, m = image.shape
    s = filter.shape[0]
    assert filter.shape[0] == filter.shape[1], "Filter must be a square matrix"
    assert s % 2 == 1, "Filter size must be an odd number"

    # Pad the image with zeros
    pad_width = s // 2
    padded_image = np.pad(image, pad_width, mode='constant', constant_values=0)

    # Prepare the output array
    output_array = np.zeros_like(image)

    # ... convolution vs correlation -> flip kernel
    if flip_filter:
        filter = np.flip(filter)

    # Perform the convolution
    for i in range(n):
        for j in range(m):
            # Extract sliding window
            window = padded_image[i:i+s, j:j+s]
            # Perform element-wise multiplication and sum the result
            output_array[i, j] = np.sum(window * filter)
    
    return output_array


mock_image = cat[:5, :5]



numpy_conv = convolve_np(mock_image, conv_filter)
numpy_conv_no_flip = convolve_np(mock_image, conv_filter, flip_filter=False)


scipy_conv = convolve(mock_image, conv_filter, mode = "constant", cval = 0)
scipy_conv


scipy_corr = correlate(mock_image, conv_filter, mode = "constant", cval = 0)
scipy_corr


scipy_conv_flip = np.flip(scipy_conv)
scipy_conv_flip


assert np.allclose(scipy_conv, numpy_conv)
assert np.allclose(scipy_corr, numpy_conv_no_flip)


np.allclose(scipy_corr, scipy_conv_flip, rtol = 0.12)


plot_image_subplots(
    [
    scipy_conv, 
    scipy_corr,
    scipy_conv_flip, 
    ], 
    titles = [
    "Convolution",
    "Correlation",
    "Convolution Flipped"
    ],
    no_ticks = False
)








# identity
identity_filter = np.array([
    [0,0,0], 
    [0,1,0],
    [0,0,0]
])


plot_heatmaps(
    [identity_filter], 
    titles=["Identity filter"], 
    ncols=1, 
    figsize_ver = 2
)


 # filter with 1, 1, 1 does nothing
ones_filter = np.ones([3, 3])


minus_ones_filter = ones_filter.copy() * -1
minus_ones_filter


plot_convolutions(
    cat, 
    filters = [
        identity_filter, 
        ones_filter, 
        minus_ones_filter
    ],
    titles = [
        "Identity",
        "Ones",
        "Minus ones"
    ]  
)





### Mean Filter - Box Blurr


# mean makes it blurry
# How is blurr useful -> get rid of noise (see also Gaussian blurr)
def mean_filter(s):
    # Box blurr
    return np.ones([s, s]) / s**2


plot_heatmaps([mean_filter(3)], titles =  ["Mean filter"], ncols = 1, figsize_ver = 2)


eye = cat[220:420, 200:400]


filter_sizes = [3, 5, 7]
mean_filters = [mean_filter(s) for s in filter_sizes]
mean_filter_titles = [f"Mean filter ${s} \\times {s}$" for s in filter_sizes]


plot_convolutions(
    eye,
    filters = [identity_filter] + mean_filters,
    titles = ["Identity"] + mean_filter_titles, 
    ncols = 4
)


filter_size = 11
blur_scipy = convolve(cat, mean_filter(filter_size))
blur_cv = cv2.blur(cat, (filter_size, filter_size))




plot_image_subplots(
    [
        blur_scipy,
        blur_cv,
    ], 
    titles = [
        "Numpy",
        "OpenCV"
    ],
    ncols = 2)


blur_scipy.shape, blur_cv.shape


idx_start = 5
idx_end = -6


np.allclose(
    blur_scipy[idx_start:idx_end, idx_start:idx_end], 
    blur_cv[idx_start:idx_end, idx_start:idx_end],
)


np.allclose(
    blur_scipy[:idx_start, :], 
    blur_cv[:idx_start, :],
)


np.allclose(
    blur_scipy[:idx_start, :], 
    blur_cv[:idx_start, :],
    rtol = 0.1
)





blur_scipy = convolve(cat, mean_filter(filter_size), mode="constant")
blur_cv = cv2.blur(cat, (filter_size, filter_size), borderType=cv2.BORDER_CONSTANT)


np.allclose(
    blur_scipy, 
    blur_cv,
)





def gaussian_kernel(size, sigma = 1.0):
    """Generate a (size x size) Gaussian kernel with standard deviation sigma.
    
    The size parameter must be an odd number.
    """
    assert size % 2 == 1, "Size must be an odd number."
    
    # Create an (size x size) grid of (x, y) coordinates
    ax = np.arange(-size // 2 + 1, size // 2 + 1)
  
    xx, yy = np.meshgrid(ax, ax)

    
    # Calculate the Gaussian function
    kernel = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))
    
    # Normalize the kernel to ensure the sum is 1
    kernel = kernel / np.sum(kernel)
    
    return kernel


gauss_1d = [
    cv2.getGaussianKernel(3, 0).T,
    cv2.getGaussianKernel(5, 0).T,
    cv2.getGaussianKernel(7, 0).T,
    cv2.getGaussianKernel(3, 0.5).T,
    cv2.getGaussianKernel(5, 0.5).T, 
    cv2.getGaussianKernel(7, 0.5).T, 
    cv2.getGaussianKernel(3, 1).T, 
    cv2.getGaussianKernel(5, 1).T, 
    cv2.getGaussianKernel(7, 1).T, 
]


plot_heatmaps(gauss_1d, ncols = 3, nrows=3)





gauss_approx_3 = np.array([
    [1, 2, 1],
    [2, 4, 2],
    [1, 2, 1]
]) / 16
gauss_approx_3


gauss_3 = gaussian_kernel(3)
gauss_3


plot_heatmaps([gauss_3, gauss_approx_3, ])


np.allclose(gauss_3, gauss_approx_3), np.allclose(gauss_3, gauss_approx_3, rtol = 0.25)


gauss_approx_5 = np.array([
    [1,  4,  7,  4, 1],
    [4, 16, 26, 16, 4],
    [7, 26, 41, 26, 7],
    [4, 16, 26, 16, 4],
    [1,  4,  7,  4, 1]
]) / 273
gauss_approx_5


gauss_5 = gaussian_kernel(5)
gauss_5


plot_heatmaps([gauss_5, gauss_approx_5])


np.allclose(gauss_5, gauss_approx_5), np.allclose(gauss_5, gauss_approx_5, rtol = 0.25)


gauss_approx_7 = np.array([
    [  0,   0,   1,   2,   1,   0,   0],
    [  0,   3,  13,  22,  13,   3,   0],
    [  1,  13,  59,  97,  59,  13,   1],
    [  2,  22,  97, 159,  97,  22,   2],
    [  1,  13,  59,  97,  59,  13,   1],
    [  0,   3,  13,  22,  13,   3,   0],
    [  0,   0,   1,   2,   1,   0,   0]
]) / 1003




gauss_7 = gaussian_kernel(7)



plot_heatmaps([gauss_7, gauss_approx_7])


np.allclose(gauss_7, gauss_approx_7), np.allclose(gauss_7, gauss_approx_7, rtol = 0.9)


eye = cat[230:300, 200:300]


plot_convolutions(eye, filters = [
    identity_filter, 
    gauss_3, 
    gauss_5, 
    gauss_7, 
    identity_filter, 
    gauss_approx_3, 
    gauss_approx_5, 
    gauss_approx_7, 

], ncols=4, nrows=2)


plt.imshow( cv2.GaussianBlur(cat, (21, 21), 0), cmap = "gray")

















avg_filter = np.array([[1, 2, 1]])
diff_filter = np.array([[1, 0, -1]])


plot_heatmaps([
    avg_filter,
    diff_filter
], figsize_ver = 1.2)














# elements for edge detection - Sobel
hor_edge_filter = np.array([
    [1, 0, -1],
    [2, 0, -2],
    [1, 0, -1]
])
ver_edge_filter = np.array([
    [1, 2, 1],
    [0, 0, 0],
    [-1, -2, -1]
])


plot_heatmaps(
    [
        ver_edge_filter,
        hor_edge_filter
    ],
    titles = [
        "Vertical Edge Filter",
        "Horizontal Edge Filter"
    ] 
)


v = 0.4
plot_convolutions(
    cat, 
    filters =[
        hor_edge_filter,
        hor_edge_filter, 
        ver_edge_filter, 
        ver_edge_filter, 
    ], 
    titles = [
        "Hor f",
        "Hor f",
        "ver",
        "Hor v"
    ],
    subplot_kwargs = [
        {},
        {"vmin": -v, "vmax": v},
        {},
        {"vmin": -v, "vmax": v}
    ],
    nrows = 2, 
    ncols = 2
)



# Apply Sobel operator
sobel_x = sobel(cat, axis=0)
sobel_y = sobel(cat, axis=1)

# Combine the two gradients
sobel_combined = np.hypot(sobel_x, sobel_y)



edges_combined = np.hypot(convolve(cat, hor_edge_filter), convolve(cat, hor_edge_filter))


sobel_x.shape


sobel_combined.min(), sobel_combined.max()


plt.imshow(edges_combined, cmap = "gray", vmin=0.4, vmax=1)
plt.show()


cat.dtype



dst = cv2.cornerHarris(np.float32(cat), blockSize=2, ksize=3, k=0.04)
dst.max(), dst.min()


plt.imshow(dst, cmap='gray', vmin=-0.03, vmax=0.01)
plt.show()





dst = cv2.cornerHarris(np.float32(cat), blockSize=2, ksize=3, k=0.04)

r = cat.copy()
g = cat.copy()
b = cat.copy()

# Makes dots bigger
dst = cv2.dilate(dst, np.ones((5, 5), np.uint8))
 
# Threshold for an optimal value, it may vary depending on the image.
limit_value = 0.02
r[dst>limit_value*dst.max()]=1
g[dst>limit_value*dst.max()]=0
b[dst>limit_value*dst.max()]=0

rgb = np.dstack((r,g,b))


plt.imshow(rgb)
plt.show()




















kernel = np.ones((5, 5), np.uint8)
kernel_big = np.ones((11, 11), np.uint8)
image = cat

plot_image_subplots(
    [
        image, 
        cv2.dilate(cv2.erode(image, kernel, iterations=1), kernel, iterations = 1), 
        cv2.erode(cv2.dilate(image, kernel, iterations=1), kernel, iterations = 1), 
        cv2.erode(image, kernel, iterations=1), 
        cv2.erode(image, kernel, iterations=5), 
        cv2.erode(image, kernel_big, iterations=1),
        cv2.dilate(image, kernel, iterations=1),
        cv2.dilate(image, kernel, iterations=5), 
        cv2.dilate(image, kernel_big, iterations=1), 
    ], 
    titles = [
        "Original Image",
        "Opening - Erode then Dilate",
        "Closing - Dilate then Erode",
        "Erode",
        "Erode  - More Iterations",
        "Erode - Bigger Kernel",
        "Dilate",
        "Dilate - More iterations",
        "Dilate - Bigger Kernel",
    ],
    nrows=3, 
    ncols = 3, 
    figsize_ver=10
)








# Load and preprocess the MNIST dataset
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

# Normalize the images to the range [0, 1]
train_images = train_images / 255.0
test_images = test_images / 255.0

# Add a channels dimension
train_images = train_images[..., tf.newaxis]
test_images = test_images[..., tf.newaxis]

# Convert labels to binary: 1 for class '8', 0 for others
train_labels = (train_labels == 8).astype(int)
test_labels = (test_labels == 8).astype(int)

# Define the CNN model
model = models.Sequential([
    layers.Conv2D(1, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Single convolutional layer with 1 filter
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(1, activation='sigmoid')  # Single output neuron for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(train_images, train_labels, epochs=1)

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'\nTest accuracy: {test_acc}')



test_images[0].shape


idx_to_plot = range(4*8)
images_to_plot = np.array([test_images[i] for i in idx_to_plot])
predictions = model.predict(images_to_plot)
titles = [f"{prob[0]:.4f}" for prob in predictions.tolist()]




plot_image_subplots(images_to_plot, titles=titles, nrows = 4, ncols = 8)


conv_layer = model.layers[0]
kernel_weights, bias = conv_layer.get_weights()

plot_heatmaps(kernel_weights, ncols=3)


kernel_weights



